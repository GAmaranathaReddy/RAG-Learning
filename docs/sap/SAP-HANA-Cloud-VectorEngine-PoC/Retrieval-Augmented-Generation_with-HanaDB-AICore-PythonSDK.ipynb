{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Augmented Generation (RAG) PoC with Python sdk and SAP HANA Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Pre-requisite:\n",
    "\n",
    "Use the secrets folder to store your service key credentials. Credentials required for:  \n",
    "* Access to the SAP GenAI XL\n",
    "* Access to the HanaDB\n",
    "\n",
    "This guide does not illustrate how to generate embeddings using the AI Core proxy embedding model. This part is coverd in the other notebooks: \n",
    "\n",
    "* Generate-and-store-embeddings_with-HanaDB-AICore-RestAPI.ipynb\n",
    "* Generate-and-store-embeddings_with-HanaDB-AICore-PythonSDK.ipynb\n",
    "\n",
    "#### Introduction: \n",
    "In this guide we will be using a dataset that already includes the embeddings in the 'VECTOR_STR' column which has been generated for the 'TEXT' column using the text-embedding-ada-002 model. \n",
    "We will store these embeggings as REAL_VECTORS inside the SAP HANA DB and use the vector search functionality to build a Retrieval Augmented Generation (RAG) usecase with AI Core proxy LLMs. \n",
    "\n",
    "#### Step-by-step guide:\n",
    "* Loading your data from csv \n",
    "* Connection with Hana database\n",
    "* Create a new Hana table and push data into it\n",
    "* Add a new column of data type REAL_VECTOR to your data table \n",
    "* Use the TO_REAL_VECTOR function to convert the embeggings to Real Vectors (VECTOR_RE). (This is necessary for the HANA DB to understand the embeddings.) and Update the data table.\n",
    "* Connection with AI Core proxy LLMs through python sdk\n",
    "* Levarage the similarity search functions which HANA DB offers for retreving relevant context based on a query.\n",
    "* The context can then be used to formulate a prompt which is fed to an AI Core proxy Chat LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install hana_ml\n",
    "# !pip install \"sap-llm-commons[all]\" see https://github.tools.sap/AI-Playground-Projects/llm-commons\n",
    "# !pip install langchain\n",
    "# add config.json according to https://github.tools.sap/AI-Playground-Projects/llm-commons/tree/main/docs/proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Loading your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModuleNotFoundError: No module named 'shapely'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>HEADER1</th>\n",
       "      <th>HEADER2</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>VECTOR_STR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>090-040-000-Appendix_C_-_GraphScript_Cheat_She...</td>\n",
       "      <td>Appendix C - GraphScript Cheat Sheet</td>\n",
       "      <td>Weighted Path Functions</td>\n",
       "      <td>&lt;!--! subsection --&gt;\\n### WEIGHT  \\n```graphsc...</td>\n",
       "      <td>[0.015699435,0.020284351,0.0003677337,-0.00413...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>060-020-030-Basic_Vertex_Operations.md</td>\n",
       "      <td>Basic Vertex Operations</td>\n",
       "      <td>DEGREE</td>\n",
       "      <td>Returns the number of incoming and outgoing ed...</td>\n",
       "      <td>[0.018821003,0.012627394,-0.007940338,-0.00959...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>060-020-020-Basic_Graph_Operations.md</td>\n",
       "      <td>Basic Graph Operations</td>\n",
       "      <td>EDGES</td>\n",
       "      <td>Returns all edges in a graph.  \\n- EDGES(GRAPH...</td>\n",
       "      <td>[-0.013607875,0.009249507,-0.03403819,-0.03394...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  L1  L2  L3                                           FILENAME  \\\n",
       "0  273  90  40   0  090-040-000-Appendix_C_-_GraphScript_Cheat_She...   \n",
       "1   52  60  20  30             060-020-030-Basic_Vertex_Operations.md   \n",
       "2   44  60  20  20              060-020-020-Basic_Graph_Operations.md   \n",
       "\n",
       "                                HEADER1                  HEADER2  \\\n",
       "0  Appendix C - GraphScript Cheat Sheet  Weighted Path Functions   \n",
       "1               Basic Vertex Operations                   DEGREE   \n",
       "2                Basic Graph Operations                    EDGES   \n",
       "\n",
       "                                                TEXT  \\\n",
       "0  <!--! subsection -->\\n### WEIGHT  \\n```graphsc...   \n",
       "1  Returns the number of incoming and outgoing ed...   \n",
       "2  Returns all edges in a graph.  \\n- EDGES(GRAPH...   \n",
       "\n",
       "                                          VECTOR_STR  \n",
       "0  [0.015699435,0.020284351,0.0003677337,-0.00413...  \n",
       "1  [0.018821003,0.012627394,-0.007940338,-0.00959...  \n",
       "2  [-0.013607875,0.009249507,-0.03403819,-0.03394...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import some vector data from csv\n",
    "import pandas as pd\n",
    "import hana_ml\n",
    "df = pd.read_csv('./data/GRAPH_DOCU_QRC3.csv', low_memory=False)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Connection to HANA Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/secrets/ies-hana-vectordb-schema-poc-sk.json', 'r') as f:\n",
    "    hana_service_key = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00.000.00.1710842063 (CE2024.10)\n",
      "USR_5SKS2ZNTSKBBRAFPULSZIT6NR\n"
     ]
    }
   ],
   "source": [
    "from hana_ml import ConnectionContext\n",
    "\n",
    "# cc = ConnectionContext(userkey='VDB_BETA', encrypt=True)\n",
    "cc= ConnectionContext(\n",
    "    address=hana_service_key['host'],\n",
    "    port=hana_service_key['port'],\n",
    "    user=hana_service_key['user'],\n",
    "    password=hana_service_key['password'],\n",
    "    currentSchema=hana_service_key['schema'],\n",
    "    encrypt=True\n",
    "    )\n",
    "print(cc.hana_version())\n",
    "print(cc.get_current_schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create a new Hana table and push data into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table\n",
    "cursor = cc.connection.cursor()\n",
    "sql_command = '''CREATE TABLE GRAPH_DOCU_QRC3(ID BIGINT, L1 NVARCHAR(3), L2 NVARCHAR(3), L3 NVARCHAR(3), FILENAME NVARCHAR(100), HEADER1 NVARCHAR(5000), HEADER2 NVARCHAR(5000), TEXT NCLOB, VECTOR_STR NCLOB);'''\n",
    "cursor.execute(sql_command)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# Upload data into the hana table\n",
    "from hana_ml.dataframe import create_dataframe_from_pandas\n",
    "v_hdf = create_dataframe_from_pandas(\n",
    "    connection_context=cc,\n",
    "    pandas_df=df,\n",
    "    table_name=\"GRAPH_DOCU_QRC3\",\n",
    "    allow_bigint=True,\n",
    "    append=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Add a new column of data type REAL_VECTOR to your data table ((Let us call this column: VECTOR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add REAL_VECTOR column\n",
    "cursor = cc.connection.cursor()\n",
    "sql_command = '''ALTER TABLE GRAPH_DOCU_QRC3 ADD (VECTOR REAL_VECTOR(1536));'''\n",
    "cursor.execute(sql_command)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Use the TO_REAL_VECTOR function to convert the embeggings to Real Vectors and Update the data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectors from embedding strings\n",
    "cursor = cc.connection.cursor()\n",
    "sql_command = '''UPDATE GRAPH_DOCU_QRC3 SET VECTOR = TO_REAL_VECTOR(VECTOR_STR);'''\n",
    "cursor.execute(sql_command)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Connection with AI Core proxy LLMs through llm-commons python-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ML deployed model\n",
    "with open('data/secrets/genai-xl-test-instance.json') as f:\n",
    "    sk = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proxy configuration\n",
    "from ipywidgets import widgets\n",
    "import json\n",
    "import os\n",
    "import llm_commons.proxy.base\n",
    "\n",
    "# specify proxy version\n",
    "llm_commons.proxy.base.proxy_version = 'aicore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_group = '3f7513e0-0c3e-4dbf-a523-04f78fa295ca'\n",
    "\n",
    "os.environ['AICORE_LLM_AUTH_URL'] = sk['url']+\"/oauth/token\"\n",
    "os.environ['AICORE_LLM_CLIENT_ID'] = sk['clientid']\n",
    "os.environ['AICORE_LLM_CLIENT_SECRET'] = sk['clientsecret']\n",
    "os.environ['AICORE_LLM_API_BASE'] = sk[\"serviceurls\"][\"AI_API_URL\"]+ \"/v2\"\n",
    "os.environ['AICORE_LLM_RESOURCE_GROUP'] = resource_group\n",
    "os.environ['LLM_COMMONS_PROXY'] = 'aicore'\n",
    "\n",
    "llm_commons.proxy.resource_group = os.environ['AICORE_LLM_RESOURCE_GROUP']\n",
    "llm_commons.proxy.api_base = os.environ['AICORE_LLM_API_BASE']\n",
    "llm_commons.proxy.auth_url = os.environ['AICORE_LLM_AUTH_URL']\n",
    "llm_commons.proxy.client_id = os.environ['AICORE_LLM_CLIENT_ID']\n",
    "llm_commons.proxy.client_secret = os.environ['AICORE_LLM_CLIENT_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/dc008d860d221c90', config_id='bcaa04ee-bb2e-4e7f-b44f-4c374d2a42eb', config_name='gpt-4-ptu-config', deployment_id='dc008d860d221c90', model_name='gpt-4', created_at=datetime.datetime(2024, 3, 26, 9, 19, 5), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '0613PTU'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/deac9533e2d3dc51', config_id='b180ebf2-9cb1-4e86-9cc5-6f5929d0c35b', config_name='gpt-35-turbo-config', deployment_id='deac9533e2d3dc51', model_name='gpt-35-turbo', created_at=datetime.datetime(2024, 3, 26, 9, 15, 47), additonal_parameters={'executable_id': 'azure-openai', 'model_version': 'latest'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/da6a26f83dc8e241', config_id='b6edfd37-8f36-447f-a763-400e08209d05', config_name='text-embedding-ada-002-config', deployment_id='da6a26f83dc8e241', model_name='text-embedding-ada-002', created_at=datetime.datetime(2024, 3, 26, 9, 14, 21), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '2'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d9b6c4f065c1c795', config_id='0fea7f95-617a-4623-8bbc-dc6700d49fdf', config_name='gpt-35-turbo-config-1', deployment_id='d9b6c4f065c1c795', model_name='gpt-35-turbo', created_at=datetime.datetime(2024, 3, 20, 13, 2, 38), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '1106PTU'}, custom_prediction_suffix=None)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm_commons.proxy.identity import AICoreProxyClient\n",
    "\n",
    "aic_proxy_client = AICoreProxyClient()\n",
    "aic_proxy_client.get_deployments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Embedding model: Replace the deployment_id with your resource group deployment id for 'text-embedding-ada-002-v2'\n",
    "from llm_commons.langchain.proxy import init_embedding_model, init_llm\n",
    "embedding_model = init_embedding_model('text-embedding-ada-002-v2', \n",
    "                                 proxy_client=aic_proxy_client, \n",
    "                                 deployment_id='da6a26f83dc8e241', \n",
    "                                 api_base=llm_commons.proxy.api_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Chat model: Replace the deployment_id with your resource group deployment id for 'gpt-35-turbo'\n",
    "\n",
    "llm = init_llm('gpt-35-turbo', \n",
    "               proxy_client = aic_proxy_client,\n",
    "               temperature=0., \n",
    "               max_tokens=256, \n",
    "               deployment_id='deac9533e2d3dc51', \n",
    "               api_base=llm_commons.proxy.api_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Levarage the similarity search functions which HANA DB offers for retreving relevant context based on a query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAP HANA VectrDB provides two distance calculating similarity search functions: L2Distance() and cosine_similarity(), to enhance the platform's capability to compute vector similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping HANA vector search in a function: Here we are using the Cosine Similarity as the Similarity Search function. \n",
    "def run_vector_search(query: str, embedding_model, metric=\"COSINE_SIMILARITY\", k=4):\n",
    "    if metric == 'L2DISTANCE':\n",
    "        sort = 'ASC'\n",
    "    else:\n",
    "        sort = 'DESC'\n",
    "    query_vector = embedding_model.embed_query(query)\n",
    "    sql = '''SELECT TOP {k} \"ID\", \"HEADER1\", \"HEADER2\", \"TEXT\"\n",
    "        FROM \"GRAPH_DOCU_QRC3\"\n",
    "        ORDER BY \"{metric}\"(\"VECTOR\", TO_REAL_VECTOR('{qv}')) {sort}'''.format(k=k, metric=metric, qv=query_vector, sort=sort)\n",
    "    hdf = cc.sql(sql)\n",
    "    df_context = hdf.head(k).collect()\n",
    "    # context = ' '.join(df_context['TEXT'].astype('string'))\n",
    "    return df_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>HEADER1</th>\n",
       "      <th>HEADER2</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211</td>\n",
       "      <td>Complex GraphScript Examples</td>\n",
       "      <td>GraphScript Procedure Example</td>\n",
       "      <td>The following example depicts a more complex e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>Graph Traversal Statements</td>\n",
       "      <td>Dijkstra's Algorithm (DIJKSTRA)</td>\n",
       "      <td>DIJKSTRA searches for shortest paths in a weig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>Built-In Graph Algorithms</td>\n",
       "      <td>Shortest Path</td>\n",
       "      <td>```bnf\\n&lt;sssp_function&gt; ::= SHORTEST_PATH '(' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>Basic Weighted Path Operations</td>\n",
       "      <td>(Constructors)</td>\n",
       "      <td>WEIGHTEDPATH objects can’t be constructed dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>GraphScript Language</td>\n",
       "      <td>None</td>\n",
       "      <td>GraphScript is an imperative programming langu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                         HEADER1                          HEADER2  \\\n",
       "0  211    Complex GraphScript Examples    GraphScript Procedure Example   \n",
       "1   90      Graph Traversal Statements  Dijkstra's Algorithm (DIJKSTRA)   \n",
       "2   83       Built-In Graph Algorithms                    Shortest Path   \n",
       "3   65  Basic Weighted Path Operations                   (Constructors)   \n",
       "4   24            GraphScript Language                             None   \n",
       "\n",
       "                                                TEXT  \n",
       "0  The following example depicts a more complex e...  \n",
       "1  DIJKSTRA searches for shortest paths in a weig...  \n",
       "2  ```bnf\\n<sssp_function> ::= SHORTEST_PATH '(' ...  \n",
       "3  WEIGHTEDPATH objects can’t be constructed dire...  \n",
       "4  GraphScript is an imperative programming langu...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the vector search\n",
    "query = \"How can I run a shortest path algorithm?\"\n",
    "df_context = run_vector_search(query=query, embedding_model=embedding_model,metric=\"COSINE_SIMILARITY\",k=5)\n",
    "df_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Using langchain framework for prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt. Do also use your knowledge from outside the given context.\n",
    "promptTemplate_fstring = \"\"\"\n",
    "You are an SAP HANA Cloud expert.\n",
    "You are provided multiple context items that are related to the prompt you have to answer.\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "promptTemplate = PromptTemplate.from_template(promptTemplate_fstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ask_llm function takes in the user query and converts them to embeddings first. Then a vector search is performed using the chosen metric and a context is retrieved.\n",
    "# The context is then leveraged to create a prompt using the langchains PrompTemplate class. The propt is then fed as input to a chat completion LLM which provides relevant response.\n",
    "\n",
    "def ask_llm(query: str, embedding_model, chat_model ,retrieval_augmented_generation: bool, metric='COSINE_SIMILARITY', k = 6) -> str:\n",
    "\n",
    "    class color:\n",
    "        RED = '\\033[91m'\n",
    "        BLUE = '\\033[94m'\n",
    "        BOLD = '\\033[1m'\n",
    "        END = '\\033[0m'\n",
    "    context = ''\n",
    "    if retrieval_augmented_generation == True:\n",
    "        print(color.RED + 'Running retrieval augmented generation.' + color.END)\n",
    "        print(color.RED + '\\nEmbedding the query string and running HANA vector search.' + color.END)\n",
    "        context = run_vector_search(query, embedding_model, metric, k)\n",
    "        print(context)\n",
    "        print(color.RED + '\\nHANA vector search returned {k} best matching documents.'.format(k=k) + color.END)\n",
    "        print(color.RED + '\\nGenerating LLM prompt using the context information.' + color.END)\n",
    "    else:\n",
    "        print(color.RED + 'Generating LLM prompt WITHOUT context information.' + color.END)\n",
    "    prompt = promptTemplate.format(query=query, context=' '.join(df_context['TEXT'].astype('string')))\n",
    "    #prompt = promptTemplate.format(query=query, context=context)    \n",
    "    print(color.RED + '\\nAsking LLM...' + color.END)\n",
    "\n",
    "    llm = chat_model\n",
    "    \n",
    "    #llm = ChatOpenAI(deployment_id=\"gpt-4\", temperature=0)\n",
    "\n",
    "    response = llm.predict(prompt)\n",
    "    \n",
    "    print(color.RED + '...completed.' + color.END)\n",
    "    print(color.RED + '\\nQuery: ' + color.END, query)\n",
    "    print(color.BLUE + '\\nResponse:' + color.BLUE)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mRunning retrieval augmented generation.\u001b[0m\n",
      "\u001b[91m\n",
      "Embedding the query string and running HANA vector search.\u001b[0m\n",
      "    ID                         HEADER1                          HEADER2  \\\n",
      "0   90      Graph Traversal Statements  Dijkstra's Algorithm (DIJKSTRA)   \n",
      "1   83       Built-In Graph Algorithms                    Shortest Path   \n",
      "2  211    Complex GraphScript Examples    GraphScript Procedure Example   \n",
      "3   65  Basic Weighted Path Operations                   (Constructors)   \n",
      "4   84       Built-In Graph Algorithms        Shortest Paths One-to-All   \n",
      "5   85       Built-In Graph Algorithms                 K-shortest Paths   \n",
      "\n",
      "                                                TEXT  \n",
      "0  DIJKSTRA searches for shortest paths in a weig...  \n",
      "1  ```bnf\\n<sssp_function> ::= SHORTEST_PATH '(' ...  \n",
      "2  The following example depicts a more complex e...  \n",
      "3  WEIGHTEDPATH objects can’t be constructed dire...  \n",
      "4  ```\\n<spoa_function> ::= SHORTEST_PATHS_ONE_TO...  \n",
      "5  ```bnf\\n<ksp_function> ::= K_SHORTEST_PATHS '(...  \n",
      "\u001b[91m\n",
      "HANA vector search returned 6 best matching documents.\u001b[0m\n",
      "\u001b[91m\n",
      "Generating LLM prompt using the context information.\u001b[0m\n",
      "\u001b[91m\n",
      "Asking LLM...\u001b[0m\n",
      "\u001b[91m...completed.\u001b[0m\n",
      "\u001b[91m\n",
      "Query: \u001b[0m I want to calculate a shortest path. How do I do that?\n",
      "\u001b[94m\n",
      "Response:\u001b[94m\n",
      "To calculate a shortest path, you can use the SHORTEST_PATH function in SAP HANA Cloud. The syntax for the SHORTEST_PATH function is as follows:\n",
      "\n",
      "```graphscript\n",
      "SHORTEST_PATH(<parent_graph_variable>, <start_vertex>, <target_vertex> [, <weight_function>] [, <edge_direction>])\n",
      "```\n",
      "\n",
      "- `<parent_graph_variable>`: The variable reference to the graph workspace.\n",
      "- `<start_vertex>`: The expression representing the start vertex of the path.\n",
      "- `<target_vertex>`: The expression representing the target vertex of the path.\n",
      "- `<weight_function>` (optional): A closure expression that calculates the weight of each edge. It takes the edge, current weight distance, and hop distance as parameters and returns a numerical value.\n",
      "- `<edge_direction>` (optional): Specifies how the function treats the direction of edges in the graph. Possible values are 'OUTGOING', 'INCOMING', and 'ANY'. 'OUTGOING' is the default.\n",
      "\n",
      "The SHORTEST_PATH function returns a WEIGHTEDPATH instance containing the shortest path within the given graph from the start vertex to the target vertex. If no path exists, an empty path is returned.\n",
      "\n",
      "Here's an example of how to use the SHORTEST_PATH function:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# query = \"Can you define a HANA graph workspace on a JSON document store collection?\"\n",
    "#query = \"How can I define a HANA graph workspace on a JSON document store collection?\"\n",
    "#query = \"How do you run a shortest path algorithm in SAP HANA Graph engine?\"\n",
    "# query = \"How can I run community detection Louvain in SAP HANA Graph?\"\n",
    "# query = \"How can I run a BFS traversal in HANA Cloud\"\n",
    "query = \"I want to calculate a shortest path. How do I do that?\"\n",
    "\n",
    "response = ask_llm(query=query, \n",
    "                   embedding_model=embedding_model,\n",
    "                   chat_model= llm, \n",
    "                   retrieval_augmented_generation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
