# What are the use cases for RAG?

There are many different use cases for RAG. The most common ones are:

## Customer support chatbots/ Question and answer chatbots / Conversational agents

Incorporating LLMs with chatbots allows them to automatically derive more accurate answers from company documents and knowledge bases. Chatbots are used to automate customer support and website lead follow-up to answer questions and resolve issues quickly.

In customer service, RAG can empower chatbots to give more accurate and contextually appropriate responses. By accessing up-to-date product information or customer data, these chatbots can provide better assistance, improving customer satisfaction. Ada, Amelia, and Rasa are real-world chatbots utilizing RAG, used by companies like Shopify, Bank of America, and Salesforce, to answer customer queries, resolve issues, complete tasks, and collect feedback.

LLMs can be customised to product/service manuals, domain knowledge, guidelines, etc. using RAG. The agent can also route users to more specialised agents depending on their query. SearchUnify has an LLM+RAG powered conversational agent for their users.

## Search augmentation

Incorporating LLMs with search engines that augment search results with LLM-generated answers can better answer informational queries and make it easier for users to find the information they need to do their jobs.

## Knowledge engine

Ask questions on your data (e.g., HR, compliance documents): Company data can be used as context for LLMs and allow employees to get answers to their questions easily, including HR questions related to benefits and policies and security and compliance questions.

## Business intelligence and analysis

Businesses can use RAG to generate market analysis reports or insights. By retrieving and incorporating the latest market data and trends, RAG can offer more accurate and actionable business intelligence, as utilized by platforms like IBM Watson Assistant, Google Cloud Dialogflow, Microsoft Azure Bot Service, and Rasa.

## Healthcare information systems

In healthcare, RAG can improve systems that provide medical information or advice. By accessing the latest medical research and guidelines, such systems can offer more accurate and safe medical recommendations. HealthTap and BuoyHealth are healthcare chatbots using RAG to provide patients with health condition information, medication advice, doctor and hospital finding services, appointment scheduling, and prescription refills.

## Legal research

Legal professionals can use RAG to quickly pull relevant case laws, statutes, or legal writings, streamlining the research process and ensuring more comprehensive legal analysis. Lex Machina and Casetext are real-world legal research chatbots using RAG to assist lawyers in finding case law, statutes, and regulations from various sources like Westlaw, LexisNexis, and Bloomberg Law, providing summaries, answering legal queries, and identifying potential legal issues.

## Content creation

In content creation, like writing articles or reports, RAG can improve the quality and relevance of the output. It does this by pulling in accurate, current information from various sources, thereby enriching the content with factual details. Jasper and ShortlyAI are examples of real-world tools that use RAG for creating content.

## Educational tools

RAG can be used in educational platforms to provide students with detailed explanations and contextually relevant examples, drawing from a vast range of educational materials. Notably, Duolingo uses RAG for personalized language instruction and feedback, while Quizlet employs it to generate tailored practice questions and provide user-specific feedback.

## Document Question Answering Systems

By providing access to proprietary enterprise document to an LLM, the responses are limited to what is provided within them. A retriever can search for the most relevant documents and provide the information to the LLM. Check out this blog for an example â€”
https://medium.com/mlearning-ai/conversing-with-documents-unleashing-the-power-of-llms-and-langchain-397838127fd

## Real-time Event Commentary

Imagine an event like a sports or a new event. A retriever can connect to real-time updates/data via APIs and pass this information to the LLM to create a virtual commentator. These can further be augmented with Text To Speech models.IBM leveraged the technology for commentary during the 2023 US Open

## Content Generation

The widest use of LLMs has probably been in content generation. Using RAG, the generation can be personalised to readers, incorporate real-time trends and be contextually appropriate. Yarnit is an AI based content marketing platform that uses RAG for multiple tasks.

## Personalised Recommendation

Recommendation engines have been a game changes in the digital economy. LLMs are capable of powering the next evolution in content recommendations. Check out Aman Chadha's blog on the utility of LLMs in recommendation systems.
